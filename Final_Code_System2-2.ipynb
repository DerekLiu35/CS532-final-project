{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpHfmpfi7Bi_"
      },
      "source": [
        "# Main Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuzhxScBIEUb",
        "outputId": "dfc914a5-17e4-42af-aadb-aa473ce46290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDSPc-bueKZv",
        "outputId": "94a573de-c06f-4024-cf53-21c1f43732aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting httpx<0.28\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.28) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<0.28) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.28) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.28) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<0.28) (0.14.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.28) (1.2.2)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: httpx\n",
            "  Attempting uninstall: httpx\n",
            "    Found existing installation: httpx 0.28.0\n",
            "    Uninstalling httpx-0.28.0:\n",
            "      Successfully uninstalled httpx-0.28.0\n",
            "Successfully installed httpx-0.27.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade \"httpx<0.28\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjN8tGgYLb3z"
      },
      "source": [
        "Define fetch_news (reading data from News Api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu5jFoKbTTfF"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "def fetch_news_api(search_keyword, start_date, end_date, sort_method):\n",
        "    ####### Settings ---> Change Variable ######\n",
        "    api_key = \"fcf6368111ce48c3b234b0a479d1dca6\"\n",
        "\n",
        "    # url definition\n",
        "    url = (\n",
        "        \"https://newsapi.org/v2/everything?\"\n",
        "        f\"q={search_keyword}&\"\n",
        "        f\"from={start_date}&\"\n",
        "        f\"to={end_date}&\"\n",
        "        f\"sortBy={sort_method}&\"\n",
        "        f\"apiKey={api_key}\"\n",
        "    )\n",
        "    #################################################\n",
        "\n",
        "    response = requests.get(url)\n",
        "    data=response.json()\n",
        "    filtered_articles = [article for article in data['articles'] if article['description'] != '[Removed]']\n",
        "    # Update the JSON structure\n",
        "    data['articles'] = filtered_articles\n",
        "\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        fetch_news_data = data\n",
        "        # Save the JSON data to a file\n",
        "        with open('news_data.json', 'w') as f:\n",
        "            json.dump(fetch_news_data, f, indent=4)\n",
        "        print(\"Data saved to 'news_data.json'\")\n",
        "        return fetch_news_data\n",
        "    else:\n",
        "        print(f\"Failed to fetch data: {response.status_code} - {response.text}\")\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQpXmFBGTUkE"
      },
      "source": [
        "extract \"title\", \"description\",\"content\" data from fetch_news_data and save into list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajiY0VDIEO4W"
      },
      "outputs": [],
      "source": [
        "def extract_news_api(fetch_news_data):\n",
        "  extract_news_data = []\n",
        "  for i in range(len(fetch_news_data['articles'])):\n",
        "    article = fetch_news_data['articles'][i]\n",
        "    title = article['title']\n",
        "    description = article['description']\n",
        "    content = article['content']\n",
        "    # if title is None\n",
        "    if title is None:\n",
        "      title = \"\"\n",
        "    # if description is None\n",
        "    if description is None:\n",
        "      description = \"\"\n",
        "    # if content is None\n",
        "    if content is None:\n",
        "      content = \"\"\n",
        "    extract_news_data.append(title + \" \" + description + \" \" + content + \" \")\n",
        "  return extract_news_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lo8m8NBMLDm"
      },
      "source": [
        "Analyze fetch_data with LLM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zDYgFBCBTE9",
        "outputId": "750d074b-e981-459d-bc51-5c660ac37269"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q torchao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-ozFRuldC9_",
        "outputId": "08256d98-c58b-4a92-ee40-c2c2a5b83bb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.3)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
            "  Downloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Downloading transformers-4.47.0-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.21.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.20.3\n",
            "    Uninstalling tokenizers-0.20.3:\n",
            "      Successfully uninstalled tokenizers-0.20.3\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.46.3\n",
            "    Uninstalling transformers-4.46.3:\n",
            "      Successfully uninstalled transformers-4.46.3\n",
            "Successfully installed tokenizers-0.21.0 transformers-4.47.0\n"
          ]
        }
      ],
      "source": [
        "# for bnb RTN nf4 quantiztion\n",
        "!pip install bitsandbytes>=0.39.0\n",
        "!pip install --upgrade accelerate transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jH6CWzNndlsQ"
      },
      "outputs": [],
      "source": [
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "referenced_widgets": [
            "19a9559984254d30aabb95d27dd7cf65",
            "beb46be67cff4cc192f97cce90df5b3a",
            "a449172f0bc14ec99d52c16cf66742e4",
            "e1cc925736194981b1609f8e077fd409",
            "dda6340fb1dd4d37bcfc5e7ed7165713",
            "316c7b5da71f4de5986240ea980c5481",
            "09d166248c3d4875a51e1c5a56824abb",
            "312d48e1324145eb949e1cab566f924f",
            "90fb589cc42540078530b6febc763f5c",
            "ae736a7e99ba40a990cde8a78d52a382",
            "0720e00d086e4864b732a9077accd71c",
            "2701e22e3ff54aefa302dbeddb6ebebc",
            "9c65e4fa65fa4508822bc9fa601ab020",
            "0b238f417357479d838c06b62b0b38ee",
            "53b52f3861a24843abe971af2e92bfe8",
            "62693c53dd964973845c1cf62a808457",
            "6eda6a7ea8194c95a89e342845e972e9",
            "2546835822cc44d388f0e099b74c4f11",
            "1d2d24414f9a447d87cbca3f0c577492",
            "e7357187d8bd40858b4621c627418b98",
            "8ffecc9770b14d29b276d627ba74ec71",
            "e084eb238ce649b99b0fba85a53a9d97",
            "ecdc920596054e59b5335db4d9761651",
            "604cef9281e64fc8a1a1480134ab751c",
            "e6c44845a9e14c7798ff6570dc63ee59",
            "0e707b160f6a4ef6b22c3d6b1fc9580c",
            "425a05260bc24fd198e01f9890a1f59c",
            "a069b0c6d966480f8d26811fed685af9",
            "e40c5959a99f467eb917a5a5dbd37baa",
            "879a43cadb0f4f6aa19b1e818f4bb3ed",
            "88c5eecfc47741b79e322ef61f88f73d",
            "29ad015080e740ae8897188109d81016",
            "15e5699b592344929c616a67a4a81fa9"
          ]
        },
        "id": "DGI3H2QhKAb1",
        "outputId": "e004ffc7-7ddb-42ef-b7ff-4e46ff462c25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train news data with LLM Model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "19a9559984254d30aabb95d27dd7cf65",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2701e22e3ff54aefa302dbeddb6ebebc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.47G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecdc920596054e59b5335db4d9761651",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/189 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification, pipeline\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "from sklearn.metrics import classification_report\n",
        "import pandas as pd\n",
        "import re\n",
        "from torchao.quantization import (\n",
        "    quantize_,\n",
        "    int8_weight_only,\n",
        "    int8_dynamic_activation_int8_weight\n",
        ")\n",
        "\n",
        "print(\"Train news data with LLM Model\")\n",
        "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, padding=True, truncation=True, token=\"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\")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "tokenizer.padding_side = \"left\"\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\", token=\"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\")\n",
        "# model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
        "\n",
        "# quantize\n",
        "#quantize_(model, int8_weight_only())\n",
        "# quantize_(model, int8_dynamic_activation_int8_weight())\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_8bit=True,\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        "   quantization_config=bnb_config,\n",
        "   token=\"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\"\n",
        ")\n",
        "\n",
        "# complie\n",
        "#model = torch.compile(model, mode=\"max-autotune\")\n",
        "# model = torch.compile(model, mode=\"reduce-overhead\", fullgraph=True)\n",
        "\n",
        "# Function to generate predictions using the model\n",
        "def generate_predictions_batched(texts, instructions, batch_size=8):\n",
        "    # Load the tokenizer and model\n",
        "    my_prompt = \"sentiment:\"\n",
        "    combined_inputs = [f\"News:\\n{text}\\n{instruction}\\n{my_prompt}\" for text, instruction in zip(texts, instructions)]\n",
        "    # Tokenize the combined inputs with padding and truncation\n",
        "    inputs = tokenizer(combined_inputs, return_tensors=\"pt\", padding=True, truncation=True, max_length=2048)\n",
        "    # Move inputs to GPU if available\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    # Generate predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=1,\n",
        "            num_beams=1,\n",
        "            do_sample=False\n",
        "        )\n",
        "    # Decode outputs\n",
        "    decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
        "    return decoded_outputs\n",
        "\n",
        "def extract_sentiment_from_output(sentimental_output):\n",
        "    # Look for \"sentiment:\" in the output and capture the text immediately following it\n",
        "    sentiment_pattern = r'sentiment:\\s*(.*?)(?:\\n|$)'\n",
        "\n",
        "    # Search for the pattern in the output\n",
        "    match = re.search(sentiment_pattern, sentimental_output)\n",
        "    if match:\n",
        "        sentiment = match.group(1).strip()\n",
        "        return sentiment\n",
        "    else:\n",
        "        print(\"No sentiment found in the output.\")\n",
        "        return \"idk\"  # Default to \"idk\" if sentiment cannot be extracted\n",
        "\n",
        "def analyze_news_api(news_content, ticker):\n",
        "    results = []\n",
        "    for news in news_content:\n",
        "        instruction = \"What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\"\n",
        "        output = generate_predictions_batched([news], [instruction])\n",
        "        predicted_sentiment = extract_sentiment_from_output(output[0])\n",
        "        results.append(predicted_sentiment)\n",
        "\n",
        "    # Save the JSON data to a file\n",
        "    with open('analyze_news.json', 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "    print(\"Data saved to 'analyze_news.json'\")\n",
        "\n",
        "    # Convert results to a DataFrame\n",
        "    return results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pBUiMtM5ukk"
      },
      "source": [
        "Main function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFNO3QLP5wjs",
        "outputId": "ceff7e8b-19f9-4b5c-9890-6db4a79ac26f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to 'news_data.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/bitsandbytes/autograd/_functions.py:315: UserWarning: MatMul8bitLt: inputs will be cast from torch.bfloat16 to float16 during quantization\n",
            "  warnings.warn(f\"MatMul8bitLt: inputs will be cast from {A.dtype} to float16 during quantization\")\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to 'analyze_news.json'\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    fetch_news_data=fetch_news_api('Nvidia', '2024-12-1','2024-12-2','popularity')\n",
        "    extract_news_data=extract_news_api(fetch_news_data)\n",
        "    analyze_news_data=analyze_news_api(extract_news_data, 'apple stock') #, \"meta-llama/Llama-3.2-1B-Instruct\",\"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\")\n",
        "\n",
        "# Standard boilerplate to call the main function\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExCK0RBqYMTl"
      },
      "source": [
        "# 1. Memory Usage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2VWogqonBHi",
        "outputId": "ca19416e-ec60-4111-d623-d4d99179b098"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7392 sha256=a491c5846879c351af1fd212e3f6b6c9dfda49701fdec8a81e73b25682aedc42\n",
            "  Stored in directory: /root/.cache/pip/wheels/a9/8a/bd/81082387151853ab8b6b3ef33426e98f5cbfebc3c397a9d4d0\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GPUtil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3I_GZXgGlzjc",
        "outputId": "d5ce59d6-c5fd-4bd7-88f6-280d750d3336"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to 'news_data.json'\n",
            "Data saved to 'analyze_news.json'\n",
            "Relative CPU Memory Usage: 0.04 GB\n",
            "Peak GPU Memory Usage (PyTorch): 3.67 GB\n",
            "Current GPU Memory Usage (GPUtil): 3.55 GB\n"
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "import GPUtil\n",
        "\n",
        "def memory_usage_api(func, *args, **kwargs):\n",
        "    # CPU memory reset\n",
        "    previous_memory = psutil.virtual_memory()\n",
        "    baseline_memory = previous_memory.total - previous_memory.available\n",
        "    peak_memory = [baseline_memory]\n",
        "    # Reset GPU peak memory\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    # Execute the main function\n",
        "    func(*args, **kwargs)\n",
        "\n",
        "    # After Execution\n",
        "    after_memory = psutil.virtual_memory()\n",
        "    current_used_memory = after_memory.total - after_memory.available\n",
        "    cpu_total = (current_used_memory - baseline_memory)/ (1024 ** 3)  # Convert bytes to GB\n",
        "\n",
        "    # Get peak GPU memory usage (PyTorch)\n",
        "    gpu_max_memory = torch.cuda.max_memory_reserved() / (1e9)  # Convert bytes to GB\n",
        "    # Get current GPU memory usage (GPUtil)\n",
        "    gpus = GPUtil.getGPUs()\n",
        "    if gpus:\n",
        "        gpu_memory_used = gpus[0].memoryUsed / 1024  # Convert MB to GB\n",
        "    else:\n",
        "        gpu_memory_used = 0\n",
        "\n",
        "    # print out\n",
        "    print(f\"Relative CPU Memory Usage: {cpu_total:.2f} GB\")\n",
        "    print(f\"Peak GPU Memory Usage (PyTorch): {gpu_max_memory:.2f} GB\")\n",
        "    print(f\"Current GPU Memory Usage (GPUtil): {gpu_memory_used:.2f} GB\")\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    memory_usage_api(main)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Ny4ghj2Bqs"
      },
      "source": [
        "# 2. Throughput (=Total Articles/Total Response Time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dM0YtfYnfwBj",
        "outputId": "28d8a30b-9f93-47b2-a8fd-965228137570"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to 'news_data.json'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:633: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to 'analyze_news.json'\n",
            "Response Time: 138.98 seconds\n",
            "Total Article Count: 97 articles\n",
            "Total Throughput: 1.43 seconds/article\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "def response_time_api(func, *args, **kwargs):\n",
        "    #### Response Time\n",
        "    # Start timing for response time\n",
        "    response_start_time = time.time()\n",
        "    # Execute the main function\n",
        "    func(*args, **kwargs)\n",
        "    # End timing for response time\n",
        "    response_end_time = time.time()\n",
        "    # Calculate response time\n",
        "    response_time = response_end_time - response_start_time\n",
        "    # Print response time\n",
        "    print(f\"Response Time: {response_time:.2f} seconds\")\n",
        "    return response_time\n",
        "\n",
        "def article_count_api():\n",
        "    read_json_file=pd.read_json('analyze_news.json')\n",
        "    article_count=len(read_json_file)\n",
        "    print(f\"Total Article Count: {article_count} articles\")\n",
        "    return article_count\n",
        "\n",
        "def throughput_calculate_api():\n",
        "    response_time=response_time_api(main)\n",
        "    article_count=article_count_api()\n",
        "    throughput=response_time/article_count\n",
        "    print(f\"Total Throughput: {throughput:.2f} seconds/article\")\n",
        "    return throughput\n",
        "\n",
        "# Run the main function with measurements\n",
        "if __name__ == \"__main__\":\n",
        "    throughput_calculate_api()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWxciBVh1Reo"
      },
      "source": [
        "# 3. Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrJYnO-D64aq"
      },
      "source": [
        "get true label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3YuZVWVkTy3i",
        "outputId": "145b834d-ec67-4dcd-937b-42603fe78c54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data saved to 'news_data.json'\n",
            "Data saved to 'analyze_news_openai.json'\n",
            "['positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'positive', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'neutral', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'negative', 'Negative', 'positive', 'neutral', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'neutral', 'negative', 'positive', 'positive', 'positive', 'positive', 'Positive', 'positive', 'negative', 'positive', 'positive', 'neutral', 'positive', 'positive', 'negative', 'positive', 'positive', 'negative', 'negative', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative', 'positive', 'neutral', 'negative', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'positive', 'neutral', 'positive', 'negative', 'negative', 'negative', 'neutral', 'positive', 'negative', 'positive', 'positive', 'positive', 'neutral', 'positive', 'positive', 'positive', 'negative', 'negative', 'positive', 'negative']\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import os\n",
        "import re\n",
        "\n",
        "def analyze_news_openai(news_content, api_key):\n",
        "    openai.api_key = api_key\n",
        "    results = []\n",
        "    for news in news_content:\n",
        "        instruction = \"What is the sentiment of this news? Please choose an answer from {negative/neutral/positive}.\"\n",
        "        completion = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": f\"{news}\\n{instruction}\\n\"\n",
        "                }\n",
        "            ]\n",
        "        )\n",
        "        # Get the response content\n",
        "        sentiment_response = completion.choices[0].message.content.strip()\n",
        "\n",
        "        # Extract the sentiment (positive, negative, neutral)\n",
        "        match = re.search(r\"(positive|negative|neutral)\", sentiment_response, re.IGNORECASE)\n",
        "        sentiment_extract = match.group() if match else \"unknown\"  # Default to \"unknown\" if no match found\n",
        "        results.append(sentiment_extract)\n",
        "\n",
        "    # Save the results to JSON\n",
        "    with open('analyze_news_openai.json', 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "    print(\"Data saved to 'analyze_news_openai.json'\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Replace with your actual API key for news API and OpenAI API\n",
        "    news_api_key = \"your_news_api_key\"\n",
        "    openai_api_key = \"\"\n",
        "    os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "    client = OpenAI()\n",
        "    # Fetch and analyze news articles\n",
        "    fetch_news_data=fetch_news_api('Nvidia', '2024-12-1','2024-12-2','popularity')\n",
        "    extract_news_data=extract_news_api(fetch_news_data)\n",
        "    sentiments = analyze_news_openai(extract_news_data, openai_api_key)\n",
        "    print(sentiments)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My-MaaTcr9Dw"
      },
      "source": [
        "calculate accuracy with confusion metrics using predicted_labels and true_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HBGZlLj-lt_r",
        "outputId": "6da06aef-b701-4128-b3c0-fbea6d752bf9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "                 Predicted Positive  Predicted Negative  Predicted Neutral\n",
            "Actual Positive                  30                   1                 26\n",
            "Actual Negative                   2                  18                  9\n",
            "Actual Neutral                    2                   2                  5\n",
            "\n",
            "Accuracy: 54.64%\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import json\n",
        "\n",
        "def accuracy_matrix_api():\n",
        "    # open each json file and read list\n",
        "    with open('analyze_news.json', 'r', encoding='utf-8') as predicted_label:\n",
        "      predicted_labels = json.load(predicted_label)\n",
        "\n",
        "    with open('analyze_news_openai.json', 'r', encoding='utf-8') as true_label:\n",
        "      true_labels = json.load(true_label)\n",
        "\n",
        "    # Calculate confusion matrix\n",
        "    conf_matrix = confusion_matrix(true_labels, predicted_labels, labels=[\"positive\", \"negative\", \"neutral\"])\n",
        "\n",
        "    # Display confusion matrix as a DataFrame\n",
        "    conf_matrix_df = pd.DataFrame(conf_matrix, index=[\"Actual Positive\", \"Actual Negative\", \"Actual Neutral\"], columns=[\"Predicted Positive\", \"Predicted Negative\", \"Predicted Neutral\"])\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix_df)\n",
        "\n",
        "    # Calculate and print accuracy\n",
        "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "    print(f\"\\nAccuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    accuracy_matrix_api()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "iI8cPFWC6K6-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0720e00d086e4864b732a9077accd71c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09d166248c3d4875a51e1c5a56824abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b238f417357479d838c06b62b0b38ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d2d24414f9a447d87cbca3f0c577492",
            "max": 2471645608,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7357187d8bd40858b4621c627418b98",
            "value": 2471645608
          }
        },
        "0e707b160f6a4ef6b22c3d6b1fc9580c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29ad015080e740ae8897188109d81016",
            "placeholder": "​",
            "style": "IPY_MODEL_15e5699b592344929c616a67a4a81fa9",
            "value": " 189/189 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "15e5699b592344929c616a67a4a81fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19a9559984254d30aabb95d27dd7cf65": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_beb46be67cff4cc192f97cce90df5b3a",
              "IPY_MODEL_a449172f0bc14ec99d52c16cf66742e4",
              "IPY_MODEL_e1cc925736194981b1609f8e077fd409"
            ],
            "layout": "IPY_MODEL_dda6340fb1dd4d37bcfc5e7ed7165713"
          }
        },
        "1d2d24414f9a447d87cbca3f0c577492": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2546835822cc44d388f0e099b74c4f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2701e22e3ff54aefa302dbeddb6ebebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c65e4fa65fa4508822bc9fa601ab020",
              "IPY_MODEL_0b238f417357479d838c06b62b0b38ee",
              "IPY_MODEL_53b52f3861a24843abe971af2e92bfe8"
            ],
            "layout": "IPY_MODEL_62693c53dd964973845c1cf62a808457"
          }
        },
        "29ad015080e740ae8897188109d81016": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "312d48e1324145eb949e1cab566f924f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316c7b5da71f4de5986240ea980c5481": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "425a05260bc24fd198e01f9890a1f59c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b52f3861a24843abe971af2e92bfe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ffecc9770b14d29b276d627ba74ec71",
            "placeholder": "​",
            "style": "IPY_MODEL_e084eb238ce649b99b0fba85a53a9d97",
            "value": " 2.47G/2.47G [00:57&lt;00:00, 42.7MB/s]"
          }
        },
        "604cef9281e64fc8a1a1480134ab751c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a069b0c6d966480f8d26811fed685af9",
            "placeholder": "​",
            "style": "IPY_MODEL_e40c5959a99f467eb917a5a5dbd37baa",
            "value": "generation_config.json: 100%"
          }
        },
        "62693c53dd964973845c1cf62a808457": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6eda6a7ea8194c95a89e342845e972e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "879a43cadb0f4f6aa19b1e818f4bb3ed": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c5eecfc47741b79e322ef61f88f73d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ffecc9770b14d29b276d627ba74ec71": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90fb589cc42540078530b6febc763f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c65e4fa65fa4508822bc9fa601ab020": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6eda6a7ea8194c95a89e342845e972e9",
            "placeholder": "​",
            "style": "IPY_MODEL_2546835822cc44d388f0e099b74c4f11",
            "value": "model.safetensors: 100%"
          }
        },
        "a069b0c6d966480f8d26811fed685af9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a449172f0bc14ec99d52c16cf66742e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_312d48e1324145eb949e1cab566f924f",
            "max": 877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_90fb589cc42540078530b6febc763f5c",
            "value": 877
          }
        },
        "ae736a7e99ba40a990cde8a78d52a382": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beb46be67cff4cc192f97cce90df5b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_316c7b5da71f4de5986240ea980c5481",
            "placeholder": "​",
            "style": "IPY_MODEL_09d166248c3d4875a51e1c5a56824abb",
            "value": "config.json: 100%"
          }
        },
        "dda6340fb1dd4d37bcfc5e7ed7165713": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e084eb238ce649b99b0fba85a53a9d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1cc925736194981b1609f8e077fd409": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae736a7e99ba40a990cde8a78d52a382",
            "placeholder": "​",
            "style": "IPY_MODEL_0720e00d086e4864b732a9077accd71c",
            "value": " 877/877 [00:00&lt;00:00, 27.6kB/s]"
          }
        },
        "e40c5959a99f467eb917a5a5dbd37baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6c44845a9e14c7798ff6570dc63ee59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_879a43cadb0f4f6aa19b1e818f4bb3ed",
            "max": 189,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88c5eecfc47741b79e322ef61f88f73d",
            "value": 189
          }
        },
        "e7357187d8bd40858b4621c627418b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecdc920596054e59b5335db4d9761651": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_604cef9281e64fc8a1a1480134ab751c",
              "IPY_MODEL_e6c44845a9e14c7798ff6570dc63ee59",
              "IPY_MODEL_0e707b160f6a4ef6b22c3d6b1fc9580c"
            ],
            "layout": "IPY_MODEL_425a05260bc24fd198e01f9890a1f59c"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}